{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "\n",
    "adm_pn = pd.read_csv(\"pneumonia/adm_pn.csv\", index_col=0)\n",
    "adm_pn = adm_pn[adm_pn[\"ICU_adm\"]==1]\n",
    "patients = pd.read_csv(\"../MIMIC-IV/mimic-iv-2/hosp/patients.csv\")\n",
    "patients_demo = pd.merge(adm_pn[[\"subject_id\", \"hadm_id\",\"admittime\"]].drop_duplicates(), patients)\n",
    "patients_demo['adm_year'] = pd.to_datetime(patients_demo['admittime']).dt.year\n",
    "patients_demo[\"adm_age\"] = patients_demo[\"adm_year\"]-(patients_demo[\"anchor_year\"] - patients_demo[\"anchor_age\"])\n",
    "patients_demo.loc[patients_demo[\"gender\"] == \"M\",\"gender\"] = 1\n",
    "patients_demo.loc[patients_demo[\"gender\"] == \"F\",\"gender\"] = 0\n",
    "\n",
    "patients_demo = patients_demo[[\"hadm_id\",'gender', 'adm_age']].drop_duplicates()\n",
    "# patients_demo.to_csv(\"pneumonia/patients_demo.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主诉"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 既往史"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "adm_pn = pd.read_csv(\"pneumonia/adm_pn.csv\", index_col=0)\n",
    "adm_pn = adm_pn[adm_pn[\"ICU_adm\"]==1]\n",
    "\n",
    "full_diag = pd.read_csv(\"pneumonia/diagnoses_full.csv\", index_col=0)\n",
    "full_diag = pd.merge(full_diag,adm_pn[['hadm_id']].drop_duplicates())\n",
    "combids = {\n",
    "    \"Congestive heart failure\":\"428\\d|I50\\d\",\n",
    "    \"Cardiacarrhythmias\":\"427\\d|I5[4-9]\\d\",\n",
    "    \"Coronary artery atherosclerosis\":\"414\\d|I25\\d\",\n",
    "    \"Pulmonarycirculation\":\"41[5-7]\\d|I2[6-8]\\d\",\n",
    "    \"Hypertention\":\"40\\d|I1\\d\",\n",
    "    \"Chronicpulmonary\":\"49\\d|J4[0-7]\\d\",\n",
    "    \"Heptic disease\":\"57[1-3]\\d|K7[0-6]\\d\",\n",
    "    \"Renal diseases\":\"58[2-6]\\d|593\\d|N0\\d|N1[7-9]\\d\",\n",
    "    \"Blood abnormal\":\"286\\d|D6[5-8]\\d\",\n",
    "    \"Diabetes\":\"250\\d|E1[0-4]\\d\",\n",
    "    \"Neuro\":\"780\\d|R40\\d\",\n",
    "    \"Immunity suppression\":\"279\\d|D80\\d|279\\d|D84\\d|042\\d|B20\\d\",\n",
    "    # \"Sepsis\":\"995\\d|038\\d|A4[0-1]\\d|R65\",\n",
    "    }\n",
    "\n",
    "for coms,icd in combids.items():\n",
    "    full_diag[coms] = 0\n",
    "    full_diag.loc[full_diag[\"icd_code\"].str.match(icd), coms] = 1\n",
    "    \n",
    "full_diag = full_diag.drop([\"subject_id\",\"seq_num\",\"icd_code\",\"icd_version\",\"infection_type\"], axis=1).groupby(['hadm_id']).max().reset_index().drop_duplicates()\n",
    "# full_diag.to_csv(\"pneumonia/patients_past.csv\")\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.bar(combids.keys(), full_diag[combids.keys()].mean())\n",
    "# plt.xlabel('Categories')\n",
    "# plt.ylabel('Probabilities')\n",
    "# plt.title('Probabilities of Medical Categories')\n",
    "\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 体格检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "adm_pn = pd.read_csv(\"pneumonia/adm_pn.csv\", index_col=0)\n",
    "\n",
    "weight = pd.read_csv(\"concepts/firstday_lab/first_day_weight.csv\")\n",
    "urine = pd.read_csv(\"concepts/firstday_lab/first_day_urine_output.csv\")\n",
    "vitalsign = pd.read_csv(\"concepts/firstday_lab/first_day_vitalsign.csv\")\n",
    "\n",
    "df = pd.merge(adm_pn, weight)\n",
    "df = pd.merge(df, urine)\n",
    "df = pd.merge(df, vitalsign)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验室指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy\n",
    "adm_pn = pd.read_csv(\"pneumonia/adm_pn.csv\", index_col=0)\n",
    "adm_pn = adm_pn[adm_pn[\"ICU_adm\"]==1]\n",
    "\n",
    "df = deepcopy(adm_pn[[\"hadm_id\", \"admittime\"]].drop_duplicates())\n",
    "\n",
    "### 将event按小时和时间分类\n",
    "input_dir = \"concepts/measurement/\"    \n",
    "for i in os.listdir(input_dir):\n",
    "    mear = pd.read_csv(\"concepts/measurement/%s\"%i)\n",
    "    df = pd.merge(df, mear, how=\"left\")\n",
    "    \n",
    "df['admittime'] = pd.to_datetime(df['admittime'])\n",
    "df['charttime'] = pd.to_datetime(df['charttime'], format=\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "df[\"lab_day\"] = (df[\"charttime\"] - df[\"admittime\"]).dt.days\n",
    "\n",
    "df = df.drop(['subject_id', 'admittime', 'charttime','specimen_id','specimen'],axis=1).groupby(['hadm_id','lab_day']).mean().reset_index()\n",
    "df = df.loc[(df[\"lab_day\"]<=3) & (df[\"lab_day\"]>=-3),df.isna().mean()<=0.9]\n",
    "df = df.sort_values(['hadm_id', 'lab_day'])\n",
    "# 根据 hadm_id 分组并保留 lab_day 最小的行\n",
    "lab_df = df.groupby('hadm_id').first().reset_index().drop_duplicates()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 影像学"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cxr_time = pd.read_csv(\"../MIMIC-IV-CXR/mimic-iv-cxr-2/mimic-cxr-2.0.0-metadata.csv\")\n",
    "cxr_time = cxr_time[[\"subject_id\", \"study_id\", \"StudyDate\"]].drop_duplicates()\n",
    "cxr_che = pd.read_csv(\"../MIMIC-IV-CXR/mimic-iv-cxr-2/mimic-cxr-2.0.0-chexpert.csv\")\n",
    "cxr_data = pd.merge(cxr_time,cxr_che)\n",
    "\n",
    "adm_pn = pd.read_csv(\"pneumonia/adm_pn.csv\", index_col=0)\n",
    "adm_pn = adm_pn[adm_pn[\"ICU_adm\"]==1]\n",
    "\n",
    "df = pd.merge(adm_pn[[\"subject_id\", \"hadm_id\", \"admittime\"]], cxr_data)\n",
    "df['admittime'] = pd.to_datetime(df['admittime'])\n",
    "df['StudyDate'] = pd.to_datetime(df['StudyDate'],format = \"%Y%m%d\")\n",
    "df[\"cxr_day\"] = (df[\"StudyDate\"] - df[\"admittime\"]).dt.days\n",
    "\n",
    "df = df.drop(['subject_id', 'admittime', 'study_id','StudyDate'], axis=1)\n",
    "df = df.groupby(['hadm_id','cxr_day']).mean().reset_index()\n",
    "df = df.loc[(df[\"cxr_day\"]<=2) & (df[\"cxr_day\"]>=-2)]\n",
    "df = df.fillna(0)\n",
    "df = df.sort_values(['hadm_id', 'cxr_day'])\n",
    "# 根据 hadm_id 分组并保留 lab_day 最小的行\n",
    "cxr_df = df.groupby('hadm_id').first().reset_index().drop_duplicates()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_with_feature_processing(data,categorical_features,continuous_features, label, testsize):\n",
    "    \n",
    "    import pandas as pd\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    data = data[categorical_features+continuous_features+label]\n",
    "    # 处理缺失值\n",
    "    imputer = SimpleImputer(strategy='mean') \n",
    "    data_filled = imputer.fit_transform(data)\n",
    "    data_filled = pd.DataFrame(data_filled, columns=data.columns)\n",
    "\n",
    "    # 特征编码\n",
    "    if len(categorical_features)>0:\n",
    "        label_encoder = LabelEncoder()\n",
    "        for feature in categorical_features:\n",
    "            data_filled[feature] = label_encoder.fit_transform(data_filled[feature])\n",
    "            \n",
    "    if len(continuous_features)>0:\n",
    "        scaler = StandardScaler()\n",
    "        data_filled[continuous_features] = scaler.fit_transform(data_filled[continuous_features])\n",
    "\n",
    "    # 划分数据集\n",
    "    X = data_filled.drop(label, axis=1)  # 假设目标变量名为'target'\n",
    "    y = data_filled[label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.astype(\"int\"), y.astype(\"int\"), test_size=testsize, random_state=42)\n",
    "\n",
    "    # 训练逻辑回归模型\n",
    "    lr_model = LogisticRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    y_pred = lr_model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test.astype('int'), y_pred.astype('int'))\n",
    "    print(\"Accuracy: %.2f\" % accuracy)  \n",
    "\n",
    "    return y_pred, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'Congestive heart failure', 'Cardiacarrhythmias', 'Coronary artery atherosclerosis', 'Pulmonarycirculation', 'Hypertention', 'Chronicpulmonary', 'Heptic disease', 'Renal diseases', 'Blood abnormal', 'Diabetes', 'Neuro', 'Immunity suppression', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Support Devices'] ['hadm_id', 'adm_age', 'ck_mb', 'ntprobnp', 'albumin', 'aniongap', 'bicarbonate', 'bun', 'calcium', 'chloride', 'creatinine', 'glucose', 'sodium', 'potassium', 'alt', 'alp', 'ast', 'bilirubin_total', 'ck_cpk', 'ld_ldh', 'Edema', 'Pneumothorax']\n",
      "Accuracy: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/t070224/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 0.8045977011494253)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(patients_demo,full_diag)\n",
    "data = pd.merge(data,lab_df)\n",
    "data = pd.merge(data,cxr_df)\n",
    "data = data.drop([\"lab_day\",\"cxr_day\"],axis=1)\n",
    "\n",
    "cate_features = [i for i in data.columns if len(set(data[i]))<=5 ]\n",
    "continous_features = [i for i in data.columns if len(set(data[i]))>5]\n",
    "print(cate_features,continous_features)\n",
    "\n",
    "continous_features.remove(\"hadm_id\")\n",
    "\n",
    "label = [\"death_event\"]\n",
    "adm_pn = pd.read_csv(\"pneumonia/adm_pn.csv\", index_col=0)\n",
    "data = pd.merge(data, adm_pn[[\"hadm_id\"]+label])\n",
    "\n",
    "# data.loc[data[\"mixed_infection\"] == \"BACT\",\"mixed_infection\"] = 1\n",
    "# data.loc[data[\"mixed_infection\"] == \"VIRUS\",\"mixed_infection\"] = 0\n",
    "# data = data.loc[data[\"mixed_infection\"].isin([1,0])]\n",
    "# data = data.loc[data[\"hadm_id\"].isin(adm_pn.loc[adm_pn[\"mixed_infection\"]==\"VIRUS\",\"hadm_id\"])]\n",
    "# data.loc[data[\"sepsis3\"] == \"t\",\"sepsis3\"] = 1\n",
    "# data.loc[data[\"sepsis3\"].isna(),\"sepsis3\"] = 0\n",
    "\n",
    "logistic_regression_with_feature_processing(data, cate_features, continous_features, label , testsize=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
